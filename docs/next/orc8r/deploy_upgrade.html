<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Upgrading from 1.0 · Magma</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="# Upgrading from v1.0"/><meta name="docsearch:version" content="next"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Upgrading from 1.0 · Magma"/><meta property="og:type" content="website"/><meta property="og:url" content="https://facebookincubator.github.io/magma/"/><meta property="og:description" content="# Upgrading from v1.0"/><meta property="og:image" content="https://facebookincubator.github.io/magma/img/docusaurus.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://facebookincubator.github.io/magma/img/docusaurus.png"/><link rel="shortcut icon" href="/magma/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/magma/js/scrollSpy.js"></script><link rel="stylesheet" href="/magma/css/main.css"/><script src="/magma/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/magma/"><img class="logo" src="/magma/img/fb.png" alt="Magma"/><h2 class="headerTitleWithLogo">Magma</h2></a><a href="/magma/versions"><h3>next</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/magma/docs/next/basics/introduction" target="_self">Docs</a></li><li class=""><a href="/magma/help" target="_self">Help</a></li><li class=""><a href="https://github.com/facebookincubator/magma" target="_self">Github</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Deploying Orchestrator</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Basics<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/magma/docs/next/basics/introduction">Introduction</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/basics/prerequisites">Prerequisites</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/basics/quick_start_guide">Quick Start Guide</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Orchestrator<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Deploying Orchestrator</h4><ul><li class="navListItem"><a class="navItem" href="/magma/docs/next/orc8r/deploy_intro">Introduction</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/orc8r/deploy_build">Building Orchestrator</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/orc8r/deploy_install">Installing Orchestrator</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/magma/docs/next/orc8r/deploy_upgrade">Upgrading from 1.0</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Orchestrator Users Guide</h4><ul><li class="navListItem"><a class="navItem" href="/magma/docs/next/orc8r/ue_metering">UE Usage Metering</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">NMS User Guide<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/magma/docs/next/nms/nms_organizations">Multi-Tenancy (Organizations)</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/nms/nms_grafana">Custom Grafana Dashboards</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Access Gateway<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Deploying AGWs</h4><ul><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/setup_deb">Setup (Bare Metal)</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/config_agw">AGW Configuration</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/enodebd">eNodeB Configuration</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/agw_110_upgrade">Upgrading from 1.0</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">AGW Development</h4><ul><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/tr069">Adding TR-069 support for an eNodeB</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/s1ap_tests">S1AP Integration Tests</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/lte/dev_notes">Developer Notes for Access Gateway</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Federation Gateway<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Deploying FeG</h4><ul><li class="navListItem"><a class="navItem" href="/magma/docs/next/feg/deploy_intro">Introduction</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/feg/deploy_build">Building Federation Gateway</a></li><li class="navListItem"><a class="navItem" href="/magma/docs/next/feg/deploy_install">Installing Federation Gateway</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"></header><article><div><span><h1><a class="anchor" aria-hidden="true" id="upgrading-from-v10"></a><a href="#upgrading-from-v10" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Upgrading from v1.0</h1>
<p>First, read through <a href="/magma/docs/next/orc8r/deploy_install">Installing Orchestrator</a> to familiarize
yourself with the installation steps. If you want to perform an online upgrade
(i.e. no downtime on NMS), this guide will walk you through the process of
concurrently deploying the 1.1.0 version of Orchestrator and NMS to your EKS
cluster. You can flip your DNS records to the new application whenever you feel
comfortable to complete the migration.</p>
<p>This guide will assume that you've already set up all the prerequisites,
including developer tooling, a Helm chart repository, and a Docker registry.</p>
<h2><a class="anchor" aria-hidden="true" id="create-a-new-root-module"></a><a href="#create-a-new-root-module" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create a New Root Module</h2>
<p>First, create a new directory somewhere to store your new root Terraform module
for the 1.1.x deployment. We have an example root module at <a href="https://github.com/facebookincubator/magma/tree/v1.1/orc8r/cloud/deploy/terraform/orc8r-helm-aws/examples/online-upgrade">https://github.com/facebookincubator/magma/tree/v1.1/orc8r/cloud/deploy/terraform/orc8r-helm-aws/examples/online-upgrade</a>
that we recommend you use for the upgrade. Copy all the files to your new
directory and change the <code>source</code> attribute of both modules in <code>main.tf</code> to
<code>github.com/facebookincubator/magma//orc8r/cloud/deploy/terraform/orc8r-aws</code> and
<code>github.com/facebookincubator/magma//orc8r/cloud/deploy/terraform/orc8r-helm-aws</code>,
respectively.</p>
<p>Once you've got this root module set up and your variables defined, run
<code>terraform init</code> in this directory.</p>
<h2><a class="anchor" aria-hidden="true" id="migrate-old-terraform-state"></a><a href="#migrate-old-terraform-state" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Migrate Old Terraform State</h2>
<p>In the following instructions, <code>OLDTF</code> refers to the directory where you put
your existing root Terraform module and its state files, and <code>NEWTF</code> refers to
the directory where you put your new root Terraform module. If you are storing
your Terraform state remotely, remember to <code>terraform pull</code> before running
<code>terraform state mv</code>.</p>
<p>Your new Terraform root module needs to know about the infrastructure
components that you created for v1.0 so it doesn't create new copies. Terraform
has a useful utility <code>terraform state mv</code> that can help accomplish this:</p>
<pre><code class="hljs css language-bash"><span class="hljs-built_in">cd</span> OLDTF
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'module.vpc'</span> <span class="hljs-string">'module.orc8r.module.vpc'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_security_group.default'</span> <span class="hljs-string">'module.orc8r.aws_security_group.default'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_ebs_volume.prometheus-ebs-eks'</span> <span class="hljs-string">'aws_ebs_volume.prometheus-ebs-eks'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_ebs_volume.prometheus-configs-ebs-eks'</span> <span class="hljs-string">'aws_ebs_volume.prometheus-configs-ebs-eks'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_iam_policy.worker_node_policy'</span> <span class="hljs-string">'aws_iam_policy.worker_node_policy'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_db_instance.default'</span> <span class="hljs-string">'module.orc8r.aws_db_instance.default'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'aws_db_instance.nms'</span> <span class="hljs-string">'module.orc8r.aws_db_instance.nms'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'module.eks'</span> <span class="hljs-string">'module.orc8r.module.eks'</span>
terraform state mv -state-out=NEWTF/terraform.tfstate <span class="hljs-string">'data.template_file.metrics_userdata'</span> <span class="hljs-string">'data.template_file.metrics_userdata'</span>
</code></pre>
<p>If you added any custom components to your v1.0 root Terraform module, you
should copy the resource blocks over to your new root module and use
<code>terraform state mv</code> to let Terraform know that they already exist.</p>
<h2><a class="anchor" aria-hidden="true" id="migrate-secrets"></a><a href="#migrate-secrets" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Migrate Secrets</h2>
<p>One change we've made in the v1.1 installation procedure is to store all the
application certificates in AWS Secretsmanager instead of on-disk in the
<code>secrets</code> sub-chart. Simply copy your old application secrets (which probably
live under the <code>secrets</code> orc8r subchart as a <code>.secrets</code> directory) to a new
temporary location on disk.</p>
<p>Then, update the application certs to include 2 new components (replace
YOURDOMAIN.COM with the domain you've reserved for Orchestrator):</p>
<pre><code class="hljs css language-bash"><span class="hljs-built_in">cd</span> MYSECRETS/certs
openssl genrsa -out fluentd.key 2048
openssl req -x509 -new -nodes -key fluentd.key -sha256 -days 3650 \
      -out fluentd.pem -subj <span class="hljs-string">"/C=US/CN=fluentd.YOURDOMAIN.COM"</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="define-terraform-variables"></a><a href="#define-terraform-variables" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Define Terraform Variables</h2>
<p>The variables that you can define in your <code>vars.tfvars</code> are documented in the
README.md in your new root Terraform module. In addition to <code>vars.tfvars</code>,
if you changed the default worker node configuration for your EKS cluster when
deploying v1.0, update that accordingly in <code>main.tf</code>. Most of this
configuration should match your v1.0 Terraform - we are aiming for a smooth
import of existing components.</p>
<p>Importantly, <code>seed_certs_dir</code> needs to point the the <code>certs</code> subdirectory
inside the temporary secrets directory you created above. At this point it is
actually safe to trash the other subdirectories (<code>envdir</code> and <code>configs</code>).</p>
<p>If you changed the EKS worker group configuration in your v1.0 deployment,
also update <code>eks_worker_groups</code> in <code>main.tf</code> to match.</p>
<h2><a class="anchor" aria-hidden="true" id="initial-terraform"></a><a href="#initial-terraform" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Initial Terraform</h2>
<pre><code class="hljs css language-bash">terraform plan -target=module.orc8r -var-file=vars.tfvars
</code></pre>
<p>Pay VERY close attention to the output of the plan to make sure that nothing
unexpected is getting deleted. If you have any questions about Terraform's
proposed plan, please drop us a question on the mailing list and we can take a
look. A misconfiguration could result in downtime or some complicated recovery
procedures.</p>
<p>For reference, our Terraform plan for this step ended up with:</p>
<pre><code class="hljs css language-bash">Plan: 21 to add, 5 to change, 5 to destroy.
</code></pre>
<p>with Elasticsearch enabled. The 5 to change/destroy were mostly launch
configurations for the EKS worker groups. If you find yourself with something
dramatically different, check over your <code>vars.tfvars</code> to make sure everything
lines up with your v1.0 Terraform configuration.</p>
<p>Most importantly, you should triple check that there is <em>nothing</em> related to
RDS in the plan (<code>aws_db_instance</code> resources). All the application components
are stateless so any mistakes while updating the EKS cluster are recoverable,
but if you drop your RDS database instances you could end up with unrecoverable
data loss.</p>
<p>When you are convinced that your new Terraform module won't break anything:</p>
<pre><code class="hljs css language-bash">terraform apply -target=module.orc8r -var-file=vars.tfvars
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="application-terraform"></a><a href="#application-terraform" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Application Terraform</h2>
<p>We will deploy the v1.1 application concurrently with the v1.0 application,
just in a different namespace and under a different Helm deployment name. At
this point, the deployment procedure is pretty much like the from-scratch
installation:</p>
<pre><code class="hljs css language-bash">$ terraform apply -target=module.orc8r-app.null_resource.orc8r_seed_secrets -var-file=vars.tfvars

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

$ terraform apply -var-file=vars.tfvars

Apply complete! Resources: 16 added, 0 changed, 0 destroyed.
</code></pre>
<p>At this point, you should see all the v1.1 application pods in the namespace
that you chose for the upgraded deployment.</p>
<h2><a class="anchor" aria-hidden="true" id="data-migrations"></a><a href="#data-migrations" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Migrations</h2>
<p>We updated the DB schemas for a few services since v1.0. You'll have to run a
pair of manual migrations to migrate the data. These scripts are idempotent
and will not affect the v1.0 deployment.</p>
<pre><code class="hljs css language-bash"><span class="hljs-comment"># Replace orc8r with your v1.1 k8s namespace if you changed the name</span>
<span class="hljs-built_in">export</span> CNTLR_POD=$(kubectl -n orc8r get pod -l app.kubernetes.io/component=controller -o jsonpath=<span class="hljs-string">'{.items[0].metadata.name}'</span>)
kubectl <span class="hljs-built_in">exec</span> -it <span class="hljs-variable">${CNTLR_POD}</span> bash

(pod)$ <span class="hljs-built_in">cd</span> /var/opt/magma/bin
(pod)$ ./m005_certifier_to_blobstore -verify

... 149 main.go:49] BEGIN MIGRATION
... 149 datastore_to_blobstore.go:136] [RUN] INSERT INTO certificate_info_blobstore (network_id,<span class="hljs-built_in">type</span>,<span class="hljs-string">"key"</span>,value,version) SELECT (<span class="hljs-string">'placeholder_network'</span>) AS network_id, (<span class="hljs-string">'certificate_info'</span>) AS <span class="hljs-built_in">type</span>, <span class="hljs-string">"key"</span>, value, generation_number FROM certificate_info_db
... 149 datastore_to_blobstore.go:84] SUCCESS
... 149 main.go:53] END MIGRATION
... 149 main.go:85] [manually verify] serial number count: 42
... 149 main.go:97] [manually verify] key-value pair: {key: REDACTED, value: id:&lt;gateway:&lt;hardware_id:<span class="hljs-string">"redacted-1234-1234-1234-redacted"</span> &gt; &gt; not_before:&lt;seconds:42 nanos:42 &gt; not_after:&lt;seconds:42 nanos:42 &gt; }
...

(pod)$ ./m008_accessd_to_blobstore -verify

... 156 main.go:49] BEGIN MIGRATION
... 156 datastore_to_blobstore.go:136] [RUN] INSERT INTO access_control_blobstore (network_id,<span class="hljs-built_in">type</span>,<span class="hljs-string">"key"</span>,value,version) SELECT (<span class="hljs-string">'placeholder_network'</span>) AS network_id, (<span class="hljs-string">'access_control'</span>) AS <span class="hljs-built_in">type</span>, <span class="hljs-string">"key"</span>, value, generation_number FROM access_control
... 156 datastore_to_blobstore.go:84] SUCCESS
... 156 main.go:52] END MIGRATION
... 156 main.go:85] [manually verify] number of operators: 1
... 156 main.go:97] [manually verify] operator-acl pair: {operator: operator:<span class="hljs-string">"admin_operator"</span> , acl: operator:&lt;operator:<span class="hljs-string">"admin_operator"</span> &gt; entities:&lt;key:<span class="hljs-string">"Id_Wildcard_Gateway"</span> value:&lt;id:&lt;wildcard:&lt;&gt; &gt; permissions:3 &gt; &gt; entities:&lt;key:<span class="hljs-string">"Id_Wildcard_Network"</span> value:&lt;id:&lt;wildcard:&lt;<span class="hljs-built_in">type</span>:Network &gt; &gt; permissions:3 &gt; &gt; entities:&lt;key:<span class="hljs-string">"Id_Wildcard_Operator"</span> value:&lt;id:&lt;wildcard:&lt;<span class="hljs-built_in">type</span>:Operator &gt; &gt; permissions:3 &gt; &gt; }
</code></pre>
<p>These 2 CLIs will spit out a few records from the migrated tables as output.
Verify that the Go structs in the output don't have all zeroed values as a
sanity check. The exact count of migrated records will differ depending on
your specific deployment but it should be nonzero for both commands.</p>
<h3><a class="anchor" aria-hidden="true" id="first-time-nms-setup"></a><a href="#first-time-nms-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>First-Time NMS Setup</h3>
<p>With the new multi-tenancy support in the NMS introduced in v1.1 you have to
create a new admin user in the <code>master</code> organization to set up access for
other tenants:</p>
<pre><code class="hljs css language-bash">kubectl <span class="hljs-built_in">exec</span> -it -n magma \
  $(kubectl -n magma get pod -l app.kubernetes.io/component=magmalte -o jsonpath=<span class="hljs-string">'{.items[0].metadata.name}'</span>) -- \
  yarn setAdminPassword master &lt;admin user email&gt; &lt;admin user password&gt;
</code></pre>
<p>When you flip DNS over to the services in the v1.1 namespace, you'll be able to
set up access for your NMS tenants at <code>https://master.nms.yourdomain.com</code>.</p>
<p>You will have to reprovision accounts for your existing users using
organizations as the old <code>nms.yourdomain.com</code> URL will no longer resolve to the
NMS. If you have a lot of users to migrate, you can do this using SQL directly
on the backing NMS MySQL database but you may find it simpler to create new
accounts for all your existing users in the frontend instead.</p>
<p>See the NMS user guides to understand how to set up tenants and users in the
new NMS.</p>
<h3><a class="anchor" aria-hidden="true" id="migrating-timeseries-data-and-configuration"></a><a href="#migrating-timeseries-data-and-configuration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Migrating Timeseries Data and Configuration</h3>
<p>We used an EBS volume mounted to a specific worker node to persist Prometheus
configuration and data in 1.0. In v1.1 we are now using PersistentVolume and
EFS to store this data so we can align with the &quot;no pets&quot; philosophy of k8s.</p>
<p>This does mean that if you want to keep your timeseries data from v1.0, you'll
have to migrate it by hand to the v1.1 EFS volume. We don't have an exact guide
for you to follow, but if you really want to keep this data, we successfully
migrated our old timeseries data with this procedure:</p>
<ol>
<li><code>kubectl scale</code> the Prometheus pods in both namespaces to 0</li>
<li>Attach and mount the EFS volume for Prometheus data in v1.1 to the <code>metrics</code>
EC2 worker node in the EC2 console or using the <code>aws</code> CLI on the node</li>
<li>SSH into the <code>metrics</code> EC2 worker node then <code>rsync</code> the Prometheus data
from the EBS volume (mounted at <code>/prometheusData</code>) to the EFS volume</li>
<li><code>kubectl scale</code> the Prometheus pods back up to 1 in both namespaces</li>
</ol>
<p>We observed a transfer rate around 3MB/sec with this procedure. You will lose
timeseries data for the duration of the data transfer.</p>
<p>If you've created a nontrivial number of alerts using the NMS, you can also
migrate those manually over to the new namespace. Use <code>kubectl cp</code> to move
all the files under <code>/etc/alertmanager</code> of the <code>orc8r-alertmanager</code> pod in 1.0
to your local host then up to the same directory of the same pod in the 1.1
namespace. You may find it more straightforward to recreate all the alerts in
the frontend instead.</p>
<h2><a class="anchor" aria-hidden="true" id="flipping-the-switch"></a><a href="#flipping-the-switch" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Flipping the Switch</h2>
<p>The v1.0.x LTE AGWs are compatible with the v1.1 Orchestrator, so you can
simply swap your DNS records over to the new application. If things don't look
good, just change the DNS records back.</p>
<p>An important change we made in 1.1 was using AWS Route53 to automatically
resolve DNS to appropriate k8s services. So instead of CNAME records in your
registrar for your domain/subdomain, use NS records instead and set the list
of nameservers to the <code>nameservers</code> output from the root Terraform module.
Because NS records don't support wildcards, you'll have to add new records
for the following subdomains:</p>
<ul>
<li><code>master.nms.</code> to access the admin UI to create and manage NMS tenants</li>
<li><code>&lt;tenant&gt;.nms.</code> for each of your tenants (replace <code>&lt;tenant&gt;</code> with the
organization ID you set up in the NMS)</li>
</ul>
<p>You can also remove the old CNAME record for the <code>nms.</code> subdomain, that will
no longer resolve to the application (all access must be through an
organization).</p>
<p>See the NMS user guides to understand how to set up tenants in the new
application.</p>
<h2><a class="anchor" aria-hidden="true" id="cleaning-up"></a><a href="#cleaning-up" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cleaning Up</h2>
<p>When you are satisfied with your v1.1 deployment and you've upgraded all your
LTE AGW's in the field, you can safely purge and clean up the old v1.0
components.</p>
<p>To delete the v1.0 application components, <code>helm delete --purge &lt;name&gt;</code>. You
can safely <code>kubectl delete namespace &lt;name&gt;</code> after this (make sure you pick
the namespace that you used for v1.0, not v1.1).</p>
<p>For the online upgrade we spun up new worker nodes to handle the extra load of
deploying 2 application versions at the same time. You can scale your EKS
worker groups back down once you purge the legacy deployment. Since we are
using only cattle in v1.1, you can delete the extra kubelet args and the
custom metrics userdata as well. For a deployment handling up to 100 LTE AGWs,
3x <code>t3.large</code> instances will do the job just fine.</p>
<p>You can safely delete all the Terraform resources in <code>legacy.tf</code> at this point
as well. After this, your root Terraform module should look a lot like
<code>examples/basic</code> in the <code>orc8r-helm-aws</code> Terraform module in Magma.</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/magma/docs/next/orc8r/deploy_install"><span class="arrow-prev">← </span><span>Installing Orchestrator</span></a><a class="docs-next button" href="/magma/docs/next/orc8r/ue_metering"><span>UE Usage Metering</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#create-a-new-root-module">Create a New Root Module</a></li><li><a href="#migrate-old-terraform-state">Migrate Old Terraform State</a></li><li><a href="#migrate-secrets">Migrate Secrets</a></li><li><a href="#define-terraform-variables">Define Terraform Variables</a></li><li><a href="#initial-terraform">Initial Terraform</a></li><li><a href="#application-terraform">Application Terraform</a></li><li><a href="#data-migrations">Data Migrations</a><ul class="toc-headings"><li><a href="#first-time-nms-setup">First-Time NMS Setup</a></li><li><a href="#migrating-timeseries-data-and-configuration">Migrating Timeseries Data and Configuration</a></li></ul></li><li><a href="#flipping-the-switch">Flipping the Switch</a></li><li><a href="#cleaning-up">Cleaning Up</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/magma/" class="nav-home"><img src="/magma/img/fb.png" alt="Magma" width="66" height="58"/></a><div><h5>Docs</h5><a href="https://github.com/facebookincubator/magma/blob/master/docs/Magma_Product_Overview.pdf">Magma Product Overview</a><a href="https://github.com/facebookincubator/magma/blob/master/docs/Magma_Specs_V1.1.pdf">Magma Spec</a></div><div><h5>Community</h5><a href="https://discord.gg/4YxZbft">Discord</a><a href="https://fb.me/magmadevsummit" target="_blank" rel="noreferrer noopener">Magma Dev Summit</a></div><div><h5>More</h5><a href="https://code.fb.com/open-source/magma/">Blog</a><a href="https://github.com/facebookincubator/magma">GitHub</a></div></section><a href="https://code.facebook.com/projects/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/magma/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Facebook</section></footer></div></body></html>